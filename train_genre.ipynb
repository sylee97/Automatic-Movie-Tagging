{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import printoptions\n",
    "import requests\n",
    "import tarfile\n",
    "import random\n",
    "import json\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix all seeds to make experiments reproducible\n",
    "torch.manual_seed(2024)\n",
    "torch.cuda.manual_seed(2024)\n",
    "np.random.seed(2024)\n",
    "random.seed(2024)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple dataloader and label binarization, \n",
    "# that is converting test labels into binary arrays of length 6\n",
    "# (number of classes) with 1 in places of applicable labels).\n",
    "class MpstDataset(Dataset):\n",
    "    def __init__(self, data_path, anno_path, transforms, split_type):\n",
    "        self.transforms = transforms\n",
    "        self.split_type= split_type\n",
    "        with open(anno_path) as fp:\n",
    "            json_data = json.load(fp)\n",
    "        samples = json_data['samples']\n",
    "        self.classes = json_data['labels']\n",
    "\n",
    "        self.imgs = [] # 이미지 이름\n",
    "        self.annos = [] # 태그 이름\n",
    "        self.annos_idx = []\n",
    "        self.data_path = data_path\n",
    "        print('loading', anno_path)\n",
    "        for sample in samples:\n",
    "            if(sample['genre'])=='Action':\n",
    "                label=0\n",
    "            elif(sample['genre'])=='Comedy':\n",
    "                label=1\n",
    "            elif(sample['genre'])=='Crime':\n",
    "                label=2 \n",
    "            elif(sample['genre'])=='Drama':\n",
    "                label=3\n",
    "            elif(sample['genre'])=='Horror':\n",
    "                label=4    \n",
    "            elif(sample['genre'])=='Romance':\n",
    "                label=5                                       \n",
    "            self.imgs.append(sample['id'])\n",
    "            self.annos.append(sample['genre'])\n",
    "            self.annos_idx.append(label)\n",
    "        for item_id in range(len(self.annos)):\n",
    "            item = self.annos[item_id]\n",
    "            vector = [cls in item for cls in self.classes]\n",
    "            self.annos[item_id] = np.array(vector, dtype=float) # labeling one-hot encoding\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        anno = self.annos[item] \n",
    "        anno_idx = self.annos_idx[item]   \n",
    "        img_path = os.path.join(self.data_path, self.split_type, self.imgs[item])\n",
    "        img_path += '.png'\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "        return img, anno, anno_idx\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('./config/cfg.yaml') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "    \n",
    "img_folder = cfg['gr_img']['path']\n",
    "split_train='train'\n",
    "split_val='val'\n",
    "dataset_train = MpstDataset(img_folder, os.path.join(img_folder, 'train', 'train.json'), None, split_train)\n",
    "dataset_val = MpstDataset(img_folder, os.path.join(img_folder, 'val', 'val.json'), None, split_val)\n",
    "print(f\"train dataset len: {len(dataset_train)}\")\n",
    "print(f\"val dataset len: {len(dataset_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate label distribution for the entire dataset (train + val)\n",
    "samples = dataset_val.annos + dataset_train.annos\n",
    "samples = np.array(samples)\n",
    "with printoptions(precision=3, suppress=True):\n",
    "    class_counts = np.sum(samples, axis=0)\n",
    "    # Sort labels according to their frequency in the dataset.\n",
    "    sorted_ids = np.array([i[0] for i in sorted(enumerate(class_counts), key=lambda x: x[1])], dtype=int)\n",
    "    print('Label Tag Distribution (count, class name):', list(zip(class_counts[sorted_ids].astype(int), np.array(dataset_val.classes)[sorted_ids])))\n",
    "    # plt.barh(range(len(dataset_val.classes)), width=class_counts[sorted_ids])\n",
    "    plt.barh(range(len(dataset_val.classes)), width=class_counts[sorted_ids])\n",
    "    plt.yticks(range(len(dataset_val.classes)), np.array(dataset_val.classes)[sorted_ids])\n",
    "    plt.gca().margins(y=0)\n",
    "    plt.grid()\n",
    "    plt.title('Label Tag Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the training parameters.\n",
    "num_workers = 0 # 8 # Number of CPU processes for data preprocessing\n",
    "lr = 1e-4 # Learning rate\n",
    "batch_size = 6\n",
    "save_freq = 1 # Save checkpoint frequency (epochs)\n",
    "max_epoch_number = 100 # Number of epochs for training \n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save path for checkpoints\n",
    "save_path = './ckpt_genre/test3'\n",
    "# Save path for logs\n",
    "logdir = './logs_genre/test3'\n",
    "\n",
    "# Run tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkpoint_save(model, save_path, epoch):\n",
    "    f = os.path.join(save_path, 'checkpoint-{:06d}.pth'.format(epoch)) # checkpoint-000000.pth\n",
    "    if 'module' in dir(model):\n",
    "        torch.save(model.module.state_dict(), f)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), f)\n",
    "    print('saved checkpoint:', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    # transforms.RandomHorizontalFlip(), # data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # normalization\n",
    "])\n",
    "\n",
    "transforms_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_folder=cfg['gr_img']['path']\n",
    "split_train='train'\n",
    "split_val='val'\n",
    "\n",
    "# Initialize the dataloaders for training.\n",
    "val_annotations = os.path.join(img_folder, 'val', 'val.json')\n",
    "train_annotations = os.path.join(img_folder, 'train','train.json')\n",
    "\n",
    "val_dataset = MpstDataset(img_folder, val_annotations, transforms_val, split_val)\n",
    "train_dataset = MpstDataset(img_folder, train_annotations, transforms_train, split_train)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True,\n",
    "                              # drop_last=True\n",
    "                              )\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "num_train_batches = int(np.ceil(len(train_dataset) / batch_size))\n",
    "num_val_batches = int(np.ceil(len(val_dataset) / batch_size))\n",
    "print(f\"num_train_batches: {num_train_batches}\")\n",
    "print(f\"num_val_batches: {num_val_batches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1=0\n",
    "# batch load\n",
    "iterator = iter(val_loader)\n",
    "\n",
    "# batch print\n",
    "inputs, classes, c_idx = next(iterator)\n",
    "print(inputs)\n",
    "print(classes)\n",
    "print(c_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader,  \n",
    "          device, logger):\n",
    "    model.to(device)\n",
    " \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = 100.0\n",
    "    \n",
    "    best_loss_model = None\n",
    "    final_model = None\n",
    "    \n",
    "    iteration = 0\n",
    "    best_loss_epoch = 0 \n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(1, max_epoch_number+1):\n",
    "        \n",
    "        if epoch==1:\n",
    "            best_loss_model = copy.deepcopy(model)\n",
    "            final_model = copy.deepcopy(model)  \n",
    "            \n",
    "        running_corrects = 0\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        for imgs, labels, lb_idx in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            lb_idx = lb_idx.to(device)\n",
    "            # print(f\"labels: {labels}\")\n",
    "            optimizer.zero_grad()\n",
    "            output = model(imgs)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            loss = criterion(output, labels.type(torch.float))\n",
    "            batch_loss_value = loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_corrects += torch.sum(preds == lb_idx)\n",
    "            # tensorboard-1 \n",
    "            logger.add_scalar('train_loss/iter', batch_loss_value, iteration) # train_loss per iter\n",
    "            train_loss.append(batch_loss_value) # \n",
    "            iteration+=1\n",
    "            \n",
    "        # validation per epoch           \n",
    "        _val_loss  = validation(model, criterion, val_loader, device, logger, iteration)\n",
    "        epoch_acc = running_corrects / len(train_dataset) * 100.\n",
    "        \n",
    "        if _val_loss < best_val_loss: # best_loss model save\n",
    "            best_val_loss = _val_loss\n",
    "            best_loss_model = copy.deepcopy(model)\n",
    "            best_loss_epoch = epoch\n",
    "            checkpoint_save(best_loss_model, save_path, best_loss_epoch)\n",
    "            \n",
    "       # tensorboard-2: val_loss/epoch\n",
    "        logger.add_scalar('val_loss/epoch' ,  _val_loss, epoch)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        # tensorboard-3: val_loss/iter\n",
    "        logger.add_scalar('_train_loss/iter', _train_loss, iteration) \n",
    "        # tensorboard-4: val_loss/epoch\n",
    "        logger.add_scalar('_train_loss/epoch', _train_loss, epoch) \n",
    "        \n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] ')\n",
    "        print(' Acc: {:.4f}% Time: {:.4f}s'.format( epoch_acc, time.time() - start_time))\n",
    "        final_model=model\n",
    "        \n",
    "    return final_model, epoch,  best_loss_model, best_loss_epoch\n",
    "\n",
    "def validation(model, criterion, val_loader, device, logger, iteration):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, lb_idx in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            lb_idx = lb_idx.to(device)\n",
    "            probs = model(imgs)\n",
    "            loss = criterion(probs, labels.type(torch.float)) # BCE loss\n",
    "            val_loss.append(loss.item())\n",
    "        _val_loss = np.mean(val_loss) # val_loader loss per batch\n",
    "    \n",
    "    return _val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logdir)\n",
    "# Tensoboard logger\n",
    "logger = SummaryWriter(logdir)\n",
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg19(pretrained=True)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "# model = models.resnet34(pretrained=True)\n",
    "# num_features = model.fc.in_features\n",
    "# model.fc = nn.Linear(num_features, 6)\n",
    "# model = models.mobilenet_v2(pretrained=True)\n",
    "# num_features = model.classifier[1].in_features\n",
    "# model.classifier[1] = nn.Linear(num_features, 6)\n",
    "num_features = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_features, 6)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Switch model to the training mode and move it to GPU.\n",
    "model.train()\n",
    "\n",
    "# If more than one GPU is available we can use both to speed up the training.\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model, epoch, best_loss_model, best_loss_epoch \\\n",
    "= train(model, optimizer, train_loader, val_loader, \n",
    "        device, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_save(model, save_path, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on the test data\n",
    "# test preprocessing\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "split_test='test'\n",
    "\n",
    "img_folder=cfg['gr_img']['path']\n",
    "split_test='test'\n",
    "\n",
    "test_annotations = os.path.join(img_folder, 'test', 'test.json')\n",
    "test_dataset = MpstDataset(img_folder, test_annotations, test_transform, split_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, \n",
    "                                num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate label distribution for the entire dataset (train + val)\n",
    "samples = test_dataset.annos\n",
    "samples = np.array(samples)\n",
    "with printoptions(precision=3, suppress=True):\n",
    "    class_counts = np.sum(samples, axis=0)\n",
    "    # Sort labels according to their frequency in the dataset.\n",
    "    sorted_ids = np.array([i[0] for i in sorted(enumerate(class_counts), key=lambda x: x[1])], dtype=int)\n",
    "    print('Label distribution (count, class name):', list(zip(class_counts[sorted_ids].astype(int), np.array(test_dataset.classes)[sorted_ids])))\n",
    "    # plt.barh(range(len(dataset_val.classes)), width=class_counts[sorted_ids])\n",
    "    plt.barh(range(len(test_dataset.classes)), width=class_counts[sorted_ids])\n",
    "    plt.yticks(range(len(test_dataset.classes)), np.array(test_dataset.classes)[sorted_ids])\n",
    "    plt.gca().margins(y=0)\n",
    "    plt.grid()\n",
    "    plt.title('Label distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "\n",
    "# test_model.eval()\n",
    "model.eval()\n",
    "start_time = time.time()\n",
    "name = []\n",
    "predictions = []\n",
    "true_data = []\n",
    "meta_tagger = pd.DataFrame()\n",
    "\n",
    "save_rt_path=cfg['genre_result']['path']\n",
    "fc_name = save_rt_path + '\\\\' + 'test3.csv'\n",
    "with torch.no_grad():\n",
    "    running_loss = 0.\n",
    "    running_corrects = 0\n",
    "    idx = 0\n",
    "    for inputs, labels, lb_idx in test_dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        lb_idx = lb_idx.to(device)\n",
    "        # print(f\"labels:{labels}\")\n",
    "        # name.append(test_dataloader.dataset.samples[idx])\n",
    "        outputs=model(inputs)\n",
    "        # outputs = test_model(inputs)\n",
    "        # print(f\"outputs size:{outputs.size()}\") # ([6, 1000])\n",
    "        # print(f\"outputs:{outputs}\")\n",
    "        _, preds = torch.max(outputs, 1) # 입력된 tensor의 dim=1을 기준으로 최댓값 반환\n",
    "        # print(f\"preds:{preds}\") # preds:tensor([4, 4, 1, 1, 2, 2], device='cuda:0')\n",
    "        # loss = criterion(outputs, labels)\n",
    "\n",
    "        # running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == lb_idx)\n",
    "        \n",
    "\n",
    "        class_names=['Action', 'Comedy', 'Crime', 'Drama', 'Horror', 'Romance']\n",
    "        \n",
    "        for i in range(len(preds)):\n",
    "            print(f'filename: {test_dataset.imgs[idx]}, [Prediction]: {class_names[preds[i]]}, (Answer): {class_names[lb_idx[i]]}')\n",
    "            # 결과 시각화  \n",
    "            # imshow(inputs.cpu().data[i], title='Prediction: ' + class_names[preds[i]])\n",
    "            name.append(test_dataset.imgs[idx])\n",
    "            predictions.append(class_names[preds[i]])\n",
    "            \n",
    "            true_data.append(class_names[lb_idx[i]])\n",
    "            idx+=1\n",
    "\n",
    "    # epoch_loss = running_loss / len(test_dataset)\n",
    "    epoch_acc = running_corrects / len(test_dataset) * 100.\n",
    "    print('[Test Phase] Acc: {:.4f}% Time: {:.4f}s'.format(epoch_acc, time.time() - start_time))\n",
    "    print(idx)\n",
    "\n",
    "meta_tagger['title'] = pd.Series(name)\n",
    "meta_tagger['Prediction Genre'] = pd.Series(predictions)\n",
    "meta_tagger['Real Genre'] = pd.Series(true_data)\n",
    "meta_tagger.to_csv(fc_name, encoding='utf-8-sig', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto_tagging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
